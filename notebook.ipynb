{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Training PoC\n",
    "\n",
    "ERNIE 5.0's elastic training idea at small scale:  \n",
    "Extract different-sized sub-models from a **single training run** and compare against classical methods (pruning, distillation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time, json, os\n",
    "\n",
    "from models import ElasticMoEModel, BaselineCNN\n",
    "from training.elastic_trainer import ElasticTrainer, StandardTrainer, get_warmup_cosine_scheduler\n",
    "from training.pruning import StructuredPruner\n",
    "from training.distillation import DistillationTrainer\n",
    "from evaluation.extract_submodel import SubModelExtractor\n",
    "from evaluation.benchmark import Benchmarker\n",
    "from visualization.plots import Visualizer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=256, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "print(f\"Train: {len(train_set)}, Test: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Elastic MoE Training\n",
    "\n",
    "3 elasticity axes trained simultaneously:\n",
    "- **Depth**: 3-6 layers active per step\n",
    "- **Width**: 4-16 experts available per step  \n",
    "- **Sparsity**: top-1 to top-3 routing per step\n",
    "\n",
    "New features:\n",
    "- **Progressive elastic**: gradually expand config space (large -> medium -> all)\n",
    "- **Warmup + cosine scheduler**: per-step LR with 5% warmup\n",
    "- **Loss weighting**: larger sub-models get higher weight [0.5, 0.2, 0.3]\n",
    "- **ColorJitter** data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 120\n",
    "LR = 0.001\n",
    "NUM_EXPERTS = 16  # 8 or 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "elastic_model = ElasticMoEModel(\n",
    "    num_classes=10, num_blocks=6, embed_dim=128,\n",
    "    moe_hidden_dim=256, num_experts=NUM_EXPERTS, default_top_k=2,\n",
    ")\n",
    "total_params = sum(p.numel() for p in elastic_model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Num experts: {NUM_EXPERTS}\")\n",
    "print(f\"Width choices: {elastic_model.width_choices}\")\n",
    "print(f\"Depth choices: {elastic_model.depth_choices}\")\n",
    "\n",
    "# OR load existing checkpoint:\n",
    "# elastic_model.load_state_dict(torch.load('checkpoints/elastic_moe.pt', weights_only=True))\n",
    "# print(\"Loaded from checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(elastic_model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "num_training_steps = EPOCHS * len(train_loader)\n",
    "num_warmup_steps = int(0.05 * num_training_steps)  # 5% warmup\n",
    "scheduler = get_warmup_cosine_scheduler(optimizer, num_warmup_steps, num_training_steps)\n",
    "\n",
    "trainer = ElasticTrainer(\n",
    "    model=elastic_model, train_loader=train_loader, val_loader=test_loader,\n",
    "    optimizer=optimizer, scheduler=scheduler, device=device,\n",
    "    use_sandwich_rule=True, use_progressive=True, loss_weights=[0.5, 0.2, 0.3],\n",
    ")\n",
    "\n",
    "elastic_history = trainer.train(num_epochs=EPOCHS)\n",
    "\n",
    "# Save checkpoint\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "torch.save(elastic_model.state_dict(), 'checkpoints/elastic_moe.pt')\n",
    "print(\"Checkpoint saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sub-Model Extraction\n",
    "\n",
    "One checkpoint -> three different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = SubModelExtractor(elastic_model)\n",
    "sub_models = extractor.extract_all_presets()\n",
    "\n",
    "# Evaluate each\n",
    "print(\"\\nSub-model accuracies:\")\n",
    "for size in ['large', 'medium', 'small']:\n",
    "    config = elastic_model.get_submodel_config(size)\n",
    "    acc = trainer.evaluate(elastic_config=config)\n",
    "    params = elastic_model.count_active_params(config)\n",
    "    print(f\"  {size:8s} | Acc: {acc:.4f} | Params: {params:,} | Config: {config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baselines\n",
    "\n",
    "Train comparison models to prove elastic training works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 1: Large CNN\n",
    "print(\"=\" * 50)\n",
    "print(\"Baseline 1: Large CNN\")\n",
    "print(\"=\" * 50)\n",
    "large_cnn = BaselineCNN(num_classes=10, size='large')\n",
    "opt = optim.AdamW(large_cnn.parameters(), lr=LR, weight_decay=1e-4)\n",
    "sch = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
    "large_trainer = StandardTrainer(large_cnn, train_loader, test_loader, opt, sch, device)\n",
    "large_history = large_trainer.train(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 2: Pruning\n",
    "print(\"=\" * 50)\n",
    "print(\"Baseline 2: Pruning (50%)\")\n",
    "print(\"=\" * 50)\n",
    "pruner = StructuredPruner(large_cnn, train_loader, test_loader, device)\n",
    "pruned_model, prune_history = pruner.prune(prune_ratio=0.5, finetune_epochs=max(5, EPOCHS // 4), lr=LR * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 3: Knowledge Distillation\n",
    "print(\"=\" * 50)\n",
    "print(\"Baseline 3: Knowledge Distillation\")\n",
    "print(\"=\" * 50)\n",
    "student = BaselineCNN(num_classes=10, size='small')\n",
    "opt = optim.AdamW(student.parameters(), lr=LR, weight_decay=1e-4)\n",
    "distiller = DistillationTrainer(\n",
    "    teacher_model=large_cnn, student_model=student,\n",
    "    train_loader=train_loader, val_loader=test_loader,\n",
    "    optimizer=opt, device=device, temperature=4.0, alpha=0.7,\n",
    ")\n",
    "distill_history = distiller.train(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 4: Small CNN from scratch\n",
    "print(\"=\" * 50)\n",
    "print(\"Baseline 4: Small CNN (from scratch)\")\n",
    "print(\"=\" * 50)\n",
    "small_cnn = BaselineCNN(num_classes=10, size='small')\n",
    "opt = optim.AdamW(small_cnn.parameters(), lr=LR, weight_decay=1e-4)\n",
    "sch = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
    "small_trainer = StandardTrainer(small_cnn, train_loader, test_loader, opt, sch, device)\n",
    "small_history = small_trainer.train(EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarker = Benchmarker(test_loader, device=device, num_warmup=5, num_runs=50)\n",
    "\n",
    "baseline_models = {\n",
    "    'large_cnn': large_cnn,\n",
    "    'pruned': pruned_model,\n",
    "    'distilled': student,\n",
    "    'small_scratch': small_cnn,\n",
    "}\n",
    "\n",
    "benchmark_results = benchmarker.run_full_comparison(elastic_model, baseline_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves\n",
    "import matplotlib\n",
    "matplotlib.use('module://matplotlib_inline.backend_inline')  # inline for notebook\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "epochs = range(1, len(elastic_history['train_loss']) + 1)\n",
    "ax1.plot(epochs, elastic_history['train_loss'], linewidth=2)\n",
    "ax1.set_xlabel('Epoch'); ax1.set_ylabel('Loss'); ax1.set_title('Elastic Training Loss'); ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(epochs, [a*100 for a in elastic_history['val_acc_large']], label='Large (6L/8E/top-2)', linewidth=2)\n",
    "ax2.plot(epochs, [a*100 for a in elastic_history['val_acc_medium']], label='Medium (4L/6E/top-2)', linewidth=2)\n",
    "ax2.plot(epochs, [a*100 for a in elastic_history['val_acc_small']], label='Small (3L/4E/top-1)', linewidth=2)\n",
    "ax2.set_xlabel('Epoch'); ax2.set_ylabel('Accuracy (%)'); ax2.set_title('Sub-Model Accuracy'); ax2.legend(); ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method comparison bar chart\n",
    "names = [r['name'] for r in benchmark_results]\n",
    "accs = [r['accuracy'] * 100 for r in benchmark_results]\n",
    "colors = ['#58a6ff' if r.get('method') == 'elastic' else '#f78166' for r in benchmark_results]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "bars = ax.bar(range(len(names)), accs, color=colors, edgecolor='white', linewidth=0.5)\n",
    "for bar, acc in zip(bars, accs):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, f'{acc:.1f}%', ha='center', fontsize=10)\n",
    "ax.set_xticks(range(len(names)))\n",
    "ax.set_xticklabels(names, rotation=30, ha='right')\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title('Elastic Training vs Baselines')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy vs Latency trade-off\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for r in benchmark_results:\n",
    "    color = '#58a6ff' if r.get('method') == 'elastic' else '#f78166'\n",
    "    ax.scatter(r['latency_ms'], r['accuracy']*100, color=color, s=150, edgecolors='white', zorder=5)\n",
    "    ax.annotate(r['name'], (r['latency_ms'], r['accuracy']*100), textcoords='offset points', xytext=(10,5), fontsize=9)\n",
    "ax.set_xlabel('Latency (ms)'); ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title('Accuracy vs Inference Speed')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expert routing heatmap\n",
    "import seaborn as sns\n",
    "\n",
    "elastic_model.eval()\n",
    "elastic_model.to(device)\n",
    "with torch.no_grad():\n",
    "    images, _ = next(iter(test_loader))\n",
    "    config = elastic_model.get_submodel_config('large')\n",
    "    _, _, router_info = elastic_model(images.to(device), elastic_config=config)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(router_info), figsize=(3.5 * len(router_info), 4))\n",
    "if len(router_info) == 1:\n",
    "    axes = [axes]\n",
    "for idx, info in enumerate(router_info):\n",
    "    probs = info['probs'].cpu().numpy().mean(axis=0).reshape(1, -1)\n",
    "    sns.heatmap(probs, ax=axes[idx], cmap='YlOrRd', annot=True, fmt='.3f',\n",
    "                xticklabels=[f'E{i}' for i in range(probs.shape[1])], yticklabels=['Prob'])\n",
    "    axes[idx].set_title(f'Block {idx}')\n",
    "plt.suptitle('Expert Routing Probabilities', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save publication-quality plots\n",
    "viz = Visualizer(save_dir='plots')\n",
    "viz.generate_all_plots(elastic_history, benchmark_results, router_info)\n",
    "print(\"High-res plots saved to plots/ folder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elastic-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
